@node Available tools
@chapter Available tools
@c TODO: I don't like this title.  -gp

The main goal of Marsyas is to provide an extensible framework that
can be used to quickly design and experiment with audio analysis and
synthesis applications.  The tools provided with the distribution,
although useful, are only representative examples of what can be
achieved using the provided components.  Marsyas is an extensible
framework for building applications, so the primary purpose of these
examples is to provide source code of working applications.

The executable files may be found in @file{bin/release/}, while the
source code for those files is in @file{apps/@{DIR@}/}.

@WANTED{descriptions of all programs; I think we cover about 30% of them}

@menu
* Collections and input files::  
* Simple Soundfile Interaction::  
* Feature Extraction::          
* Synthesis::                   
* Machine Learning::            
* Marsystem Interaction::       
* All of the above::            
* Regression tests::            
@end menu


@node Collections and input files
@section Collections and input files

Many Marsyas tools can operate on individual soundfiles or
collections of soundfiles.  A collection is a simple text
file which contain lists of soundfiles. 

@menu
* Creating collections manually::  
* mkcollection::                
@end menu


@node Creating collections manually
@subsection Creating collections manually

A simple way to create a collection is the unix ls command. 
For example: 

@example
ls /home/gtzan/data/sound/reggae/*.wav > reggae.mf
@end example

@noindent
@code{reggae.mf} will look like this:

@example
/home/gtzan/data/sound/reggae/foo.wav 
/home/gtzan/data/sound/reggae/bar.wav 
@end example

Any text editor can be used to create collection files. The only
constraint is that the name of the
collections file must have a @code{.mf} extension such as
@code{reggae.mf}.   In addition, any
line starting with the @code{#} character is ignored.  For Windows Visual
Studio, change the slash character separating directories appropriately.


@subsection Labels

Labels may be added to collections by appending tab-seperated labels
after each sound file:

@example
/home/gtzan/data/sound/reggae/foo.wav \t music
/home/gtzan/data/sound/reggae/bar.wav \t speech
@end example

This allows you to create a @qq{master} collection which includes
different kinds of labelled sound files:

@example
cat music.mf speech.mf > all.mf
@end example


@node mkcollection
@subsection @code{mkcollection}
@cindex mkcollection     
 
@code{mkcollection} is a simple utility for creating collection 
files. To create a collection of all the audio files residing 
in a directory the following command can be used: 

@example 
mkcollection -c reggae.mf -l music /home/gtzan/data/sound/
@end example

This also labels the data as @samp{music}.

All the soundfiles residing in that directory or any subdirectories
will be added to the collection.  @code{mkcollection} only will add
files with @code{.wav} and @code{ .au} extensions but
does not check that they are valid soundfiles.  In general
collection files should contain soundfiles with the same sampling rate
as Marsyas does not perform automatic sampling conversion on collections. 


@node Simple Soundfile Interaction
@section Simple Soundfile Interaction

@menu
* sfinfo::                      
* sfplay::                      
@end menu


@node sfinfo
@subsection @code{sfinfo}
@cindex sfinfo

@code{sfinfo} is a simple command-line utility for displaying 
information about a soundfile. It is also a simple 
example of how printing out the controls can show 
information like channels, sampling rate etc.  

@example 
sfinfo foo.wav 
@end example 


@node sfplay
@subsection @code{sfplay}
@cindex sfplay 

@code{sfplay} is a flexible command-line soundfile player that allows
playback of multiple soundfiles in various formats with either
real-time audio output or soundfile output. The following two example
show two extremes of using of sfplay: simple playback of foo.wav and
playing 3.2 seconds (-l) clips starting at 10.0 seconds (-s) into the
file and repeating the clips for 2.5 times (-r) writing the output to
output.wav (-f) at half volume (-g) playing each file in the
collection reggae.mf. The last command stores the MarSystem dataflow
network used in sfplay as a plugin in playback.mpl. The plugin is
essentially a textual description of the created network.  Because
MarSystems can be created at run-time the network can be loaded in a
sfplugin which is a generic executable that flows audio data through
any particular network.  Running sfplugin -p playback.mpl bar.wav will
play using the created plugin the file bar.wav. It is important to
note that although both sfplay and sfplugin have the same behavior in
this case they achieve it very different.  The main difference is that
in sfplay the network is created at compile time wheras in sfplugin
the network is created at run time.


@example
sfplay foo.wav 
sfplay -s 10.0 -l 3.2 -r 2.5 -g 0.5 foo.wav bar.au -f output.wav
sfplay -l 3.0 reggae.mf
sfplay foo.wav -p playback.mpl 
sfplugin -p playback.mpl bar.wav
@end example


@node Feature Extraction
@section Feature Extraction

@menu
* pitchextract::                
* extract::                     
* bextract::                    
@end menu


@node pitchextract
@subsection @code{pitchextract}
@cindex pitchextract

@code{pitchextract} is used to extract the fundamental frequency 
contour from monophonic audio signals. A simple sinusoidal 
playback is provided for playback of the resulting contour. 


@node extract
@subsection @code{extract}
@cindex extract

@code{extract} is a single-file executable for feature extraction.  It can be
used as part of external systems for feature extraction therefore it
outputs the results in a simple comma-separated output to stdout. For
more serious feature extraction over multiple files bextract should be
used. It can also server as a simple example of how feature extraction
is expressed in Marsyas by looking at the source code of extract.cpp.

@code{extract} will be removed from the Marsyas trunk in the near future. 

@example 
extract foo.wav 
@end example 


@node bextract
@subsection @code{bextract}
@cindex bextract

@code{bextract} is one of the most powerful executables provided by
Marsyas. It can be used for complete feature extraction and
classification experiments with multiple files. It serves as a
canonical example of how audio analysis algorithms can be expressed in
the framework. This documentation refers to the latest refactored 
version of bextract. The old-style @code{bextract} using the -e command-line 
option to specify the feature extractor is still supported but 
use of it discouraged. 

Suppose that you want to build a real-time music/speech descriminator
based on a collection of music files named music.mf and a collection
of speech files named speech.mf.  These collections can either be
created manually or using the mkcollection utility. The following
commandline will extract means and variances of timbral features 
(time-domain Zero-Crossings, Spectral Centroid, Rolloff, Flux and 
Mel-Frequency Cepstral Coefficients (MFCC) over a texture window of 1 sec.  

@example 
bextract music.mf speech.mf -w ms.arff -p ms.mpl 
bextract ms.mf -w ms.arff -p ms.mpl 
bextract -mfcc classical.mf jazz.mf rock.mf -w genre.arff
@end example 

Both of these commands are equivalent assuming that 
ms.mf is a labeled collection with the same files 
as music.mf and speech.mf. The third-command specifies 
that only the MFCC features should be extracted and is 
an example of classifying three classes. 

The results are stored in a ms.arff which is a text file storing the
feature values that can be used in the Weka machine learning environment
for experimentation with different classifiers.  After a header
describing the features (attribute in Weka terminology) it consists of
lines of comma separated feature values. Each line corresponds to a
feature vector. The attributes in the generated .arff file have long
descriptive names that show the process used to calculate the attribute.
In order to associate filenames and the subsequences of feature vectors
corresponding to them each subsequence corresponding to a file is
prefixed by the filename as a comment in the .arff file. It is a text
file that is straighforward to parse. Viewing it in a text editor will
make this clearer.

In addition to Weka, the native Marsyas kea tool can be used to perform 
evaluations (cross-validation, accuracies, confusion matrices) 
similar to Weka although with more limited functionality. 

At the same time that the features are extracted, a classifier (by
default a simple Naive Bayes classifier) is trained and when feature
extraction is completed the whole network of feature extraction and
classification is stored and can be used for real-time audio
classification directly as a Marsyas plugin stored in ms.mpl.

The resulting plugin makes a classification decision every 20ms but
aggregates the results by majority voting (using the Confidence
MarSystem) to display time-stamped output approximately every 1
second. The whole network is stored in ms.mpl which is loaded into
sfplugin and file_to_be_classified is played and classified at the same
time. The screen output shows the classification results and
confidence. The second command shows that the live run-time
classification can be integrated with @code{bextract}. In both cases 
collections can be used instead of single files. 

@example 
sfplugin -p ms.mpl music_file_to_be_classifed.wav
sfplugin -p ms.mpl speech_file_to_be_classifed.wav
bextract -e ms.mf -tc file_to_classified.wav 
bextract -e ms.mf -tc collection_to_classified.wav 
@end example 

Using the command-line option -sv turns on single vector 
feature extraction where one feature vector is extracted per file. 
The single-vector feature representation is useful for 
many Music Information Retrieval tasks (MIR) such 
as genre classification, similarity retrieval, and visualization 
of music collections. The following command can 
be used to generate a weka file for genre classification with one 
vector per file. 

@example 
./bextract -sv cl.mf ja.mf ro.mf -w genres.arff -p genres.mpl
@end example 

The resulting genres.arff file has only one feature vector line 
for each soundfile in the collections. 


Feature sets refer to collections of features that can 
be included in the feature extraction. It includes 
several individual feature sets proposed in the MIR 
and audio analysis literature as well as some common combinations 
of them. (for details and the most updated list of supported 
sets experienced users can consult the selectFeatureSet() function 
in bextract.cpp). The feature sets can be separated into three 
lagre groups depending what front-end is used: time-domain, 
spectral-domain, lpc-based. 

The following feature sets are supported (for definitions consult 
the MIR literature, check the corresponding code implementations 
and send us email with question for details you don't understand) : 

@table @samp
@item -timbral --TimbralFeatures 
      Time ZeroCrossings, Spectral  Centroid, Flux and Rolloff, 
and Mel-Frequency Cepstral Coefficients (MFCC). Equivalent to
-mfcc -zcrs -ctd -rlf -flx. This also the default extracted feature set. 

@item -spfe --SpectralFeatures
      Spectral Centroid, Flux and Rolloff. Equivalent to 
-zcrs -ctd -rlf -flx. 

@item -mfcc --MelFrequencyCepstralCoefficients
      Mel-Frequency Cepstral Coefficients.

@item -ctd --SpectralCentroid
@item -rlf -- SpectralCentroid
@item -flx --SpectralFlux
@item -zcrs --ZeroCrossings
@item -sfm --SpectralFlatnessMeasure 
@item -scf --SpectralCrestFactor
@item -lsp --LineSpectralPair 
@item -lpcc --LinearPredictionCepstralCoefficients
@end table

By default stereo files are donwmixed to mono by summing the two
channels before extracting features.  However, bextract also supports
the extraction of feature based on stereo information. There are 
feature sets that can only be extracted from stereo files. In addition 
it is possible to use any of the feature sets described above 
and extract features for both left and right channels that are 
concatenated to form a feature vector. 

@table @samp 
@item -spsf --StereoPanningSpectrumFeatures 
@item -st --stereo
      Calculate whatever feature sets are activated for both left 
and right channels.  
@end table

For example the first command calculate MFCC for both 
left and right channels.  The second command calculates 
the Stereo Panning Spectrum Features which require both 
channels and also the Spectral Centroid for both left 
and right. 

@example 
bextract -st -mfcc mymusic.mf -w mymusic.arff
bextract -spsf -st --SpectralCentroid -w mymusic.arff 
@end example 

The feature extraction can be configured in many ways 
(only some of which are possible through command-line 
options). The following options can be used to control 
various aspects of the feature extraction process
(most of the default values assume 22050 Hz sampling rate): 


@table @samp 
@item -s --start
      starting offset (in seconds) into each soundifle from which features will be extracted
@item -l --length
      length (in seconds) of each soundfile from which features will be extracted. A length of -1.0 indicates that the entire duration of the file should be used (the default behavior) 
@item -ws --winsamples
      size in samples of the analysis window (default 512) 
@item -hp --hopsamples 
      size in samples of the hop analysis size (default 512 - no overlap) 
@item -as --accSize 
      size in analysis frames of how many feature vectors are summarized 
when single vectors per file are calculated (default 1298 - approximately 30 seconds)
@item -m --memory 
      size in analysis frames of how many features vectors are summarized 
for each texture window (default 40 - approximately 1 second) 
@item -cl --classifier 
      classifier used for training and prediction (default GS - a simple Naive Bayes Classifier) 
@item -e --extractor 
      old-style specification of feature extraction maintained for backward compatibility (usage discouraged) 
@item -p --plugin 
      filename of generated Marsyas plugin (.mpl file) 
@item -w --wekafile 
      filename of generated .arff file (for Weka or kea)  
@item -tc --test 
      filename of collection or soundfile used for real-time prediction 
after a model is trained 
@end table







@node Synthesis
@section Synthesis

@menu
* phasevocoder::                
* sftransform::                 
@end menu

@node phasevocoder
@subsection @code{phasevocoder}
@cindex phasevocoder

phasevocoder is probably the most powerful and canonical example of
sound synthesis provided currently by Marsyas. It is based on the
phasevocoder implementation described by F.R.Moore in his book
@qq{Elements of Computer Music}. It is broken into individual
MarSystems in a modular way and can be used for real-time
pitch-shifting and time-scaling.
 
@example
phasevocoder -p 1.4 -s 100
@end example


@node sftransform
@subsection @code{sftransform}
@cindex sftransform

sftransform is an example of having a doubly nested 
network with two FFT/inverse FFT identity transformations. 
It's not particularly useful but show how 
to nested networks can be created.


@node Machine Learning
@section Machine Learning

@menu
* kea::                         
@end menu

@node kea
@subsection @code{kea}
@cindex kea

The previous version of Marsyas 0.1 contained machine learning 
functionality but until 2007 the new version 0.2 mostly relied on 
Weka for machine learning experiments. Although this  
situation was satisfactory for writing papers it was not possible 
to create real-time networks integrating machine learning. 
Therefore an effort was made to establish programming 
conventions for how machine learning MarSystems should be 
implemented. Last but not least we have always wanted to 
have as much functionality related to audio processing 
systems implemented natively in Marsyas. 

@code{kea} is one of the outcomes of this effort. Kea (a rare bird 
from New Zealand) is the Marsyas counterpart of Weka 
and provides similar capabilities with the command-line 
interface to Weka although much more limited (at least 
for now). 

Any weka .arff file can be used as input to kea 
although ususally the input is the extracted .arff 
files from @code{bextract}. The following command-line options 
are supported. 

@table @samp 
@item -m --mode
      specifies the mode of operation (train, distance_matrix, pca). The 
default mode is train. 
@item -cl --classifier
      the type of classifier to use if mode is train 
 Available classifiers are GS, ZEROR, SVM 
@item -w --wekefile 
      the name of the weka file 
@item -dm --distance_matrix 
      filename for the distance matrix output if mode is distance_matrix 
@end table

The main mode (train) basically performs 10-fold non-stratified 
cross-validation to evaluate the classification performance 
of the specified classifier on the provided .arff file. In addition 
to classification accuracy It outputs several other summary 
measures of the classifier's performance as well as the confusion 
matrix. The format of the output is similar to Weka. 

The mode distance_matrix is used to compute a NxN similarity matrix
based on the input .arff file containing N feature vector instances. The
output format is the one used for MIREX 2007 music similarity task. This
functionality relies on specific naming conventions related to the
Marsyas MIREX2007 submission. By default the output goes to dm.txt but
can be specified by the -dm command-line option. The following 
examples show different ways @code{kea} can be used. 

The pca mode reduces the input feature vectors by projecting 
them to the first 3 principal components using Principal 
Component Analysis (PCA). Each component is normalized 
to lie in the range [0-512]. The resulting transformed 
features are simply written to stdout. 

@example
kea -w iris.arff 
kea -m train -w iris.arff 
kea -m distance_matrix -dm dmatrix.txt -w iris.arff
kea -m pca -w iris.arff
@end example






@node Marsystem Interaction
@section Marsystem Interaction

@menu
* sfplugin::                    
* msl::                         
@end menu

@node sfplugin
@subsection @code{sfplugin}
@cindex sfplugin

sfplugin is the universal executable. Any network of Marsystems 
stored as a plugin can be loaded at run-time and sound can flow 
through the network. The following example with appropriate plugins 
will peform playback of foo.wav and playback with real time music
speech classification of foo.wav. 

@example 
sfplugin -p plugins/playback.mpl foo.wav
sfplugin -p musp_classify.mpl foo.wav
@end example 


@node msl
@subsection @code{msl}
@cindex msl

One of the most useful and powerful characteristics of Marsyas 
is the ability to create and combine MarSystems at run time. 
msl (marsyas scripting language) is a simple interpreter 
that can be used to create dataflow networks, adjust controls, 
and run sound through the network. It's used as a backend for 
user interfaces therefore it has limited (or more accurately
non-existent) editing functionality. The current syntax 
is being revised so currently it's more a proof-of-concept. 
Here is an example of creating a simple network in msl and 
playing a sound file: 

@example 
msl 
[ msl ] create Series playbacknet
[ msl ] create SoundFileSource src
[ msl ] create Gain g
[ msl ] create AudioSink dest
[ msl ] add src  > playbacknet
[ msl ] add g    > playbacknet
[ msl ] add dest > playbacknet
[ msl ] updctrl playbacknet SoundFileSource/src/string/filename technomusic.au
[ msl ] run playbacknet
@end example 

The important thing to notice is that both the creation of MarSystems 
and their assembly into networks can be done at run-time without 
having to recompile any code. If anyone would like to pick 
a project to do for Marsyas it would be to use the GNU readline 
utility for it's commandline editing capabilities and try 
to come up with some alternative syntax (I have some ideas 
in that direction). 


@node All of the above
@section All of the above

@subsection Mudbox

@WANTED{funny description of mudbox -- I'm look at you, George}

Developers interested in contributing to this mess should read
@develref{Playing in the mudbox}.


@node Regression tests
@section Regression tests

Marsyas contains a suite of tests which attempt@footnote{Somewhat
unsuccessfully, unfortunately.} to make sure that new functionality (or
bug fixes) do not cause bugs in existing (working) code.  The tests do
not require the marsyas executables to be installed (by default they
execute @file{bin/release/PROGNAME} ), but marsyas must be
compiled.

@warning{The tests also require Python to be installed.  Python is
installed by default on Linux and MacOS X machines; Windows users
may install it from @uref{http://python.org}.}

Developers interested in the inner workings of these tests may find the
information in @develref{Regression tests (devel)}.

@menu
* Sanity tests::                
* Coffee tests::                
@end menu


@node Sanity tests
@subsection Sanity tests

These are short, quick tests; on modern hardware they will take less
than 10 seconds to run.

To test, simply run

@example
scripts/regtests_sanity.py
@end example

Results will be printed on the command line, with more information in
the file @file{tests/results.log}.

These tests are not complete by any means, nor are they intended to be.
They are simply a quick test to see if anything fundamental is broken.
Since they @emph{are} so quick and easy to run, please run these tests
often.


@node Coffee tests
@subsection Coffee tests

These are a longer set of tests; they may take up to 5 minutes to
run.  They also require files that are not part of the Marsyas svn
or tarballs.  They are available on the web, see @ref{Datasets}.
The location of these files must be passed to the script, for
example

@example
scripts/commit_tests.py ../../marsyas-coffee/
@end example

Results will be printed on the command line, with more information in
the file @file{tests/results.log}.

These tests are a useful excuse for taking a coffee break.


